{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6548f38e",
   "metadata": {},
   "source": [
    "### Template for NLP project\n",
    "\n",
    "The aim of the project is to achieve the following:\n",
    " - Train a neural network that is **at least better than random guessing** on your dataset. The template contains the IMDB dataset for sentiment analysis, however, you can choose any other language related data set with the appropriate NLP task.\n",
    " - Investigate different neural network architectures (different hyperparameters, different layers, different pre-processing). Explain in the presentation, why the final network was selected! **Do not rely on black-box mechanisms.**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c548b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "# tensorflow modules\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LayerNormalization, LSTM\n",
    "import tensorflow\n",
    "\n",
    "# if you have installed a different version, replace 'r2.6'  with your version in links provided below\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b175c046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n",
      "---review with words---\n",
      "['the', 'version', 'to', 'date', 'on', 'list', 'draw', 'him', 'critical', 'very', 'love', 'to', 'by', 'br', 'of', 'its', 'tony', 'characters', 'was', 'one', 'life', 'this', 'is', 'go', 'was', 'best', 'least', 'should', 'so', 'done', 'result', 'no', 'was', 'with', 'this', 'understood', 'only', 'war', \"couldn't\", 'that', 'her', 'get', 'would', 'johnny', 'we', 'in', 'tighter', 'are', 'to', 'business', 'that', 'her', 'because', 'story', 'use', 'movies']\n"
     ]
    }
   ],
   "source": [
    "# load imdb dataset\n",
    "# links to dataset\n",
    "# original dataset: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "# version in tensorflow: https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/datasets/imdb\n",
    "\n",
    "# select your vocabulary size\n",
    "vocabularySize = 25000\n",
    "# load data (it is already pre-processed)\n",
    "# optional: add other pre.processing steps like stopword removal\n",
    "(xTrain, yTrain), (xTest, yTest) = imdb.load_data(num_words=vocabularySize)\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(xTrain), len(xTest)))\n",
    "\n",
    "# look at the respective words\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print('---review with words---')\n",
    "print([id2word.get(i, ' ') for i in xTrain[123]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e43d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words in IMDB dataset: 88584\n",
      "Words without emotes in IMDB dataset: 81397\n",
      "Example - 'love': ['joy', 'positive']\n",
      "Example - 'not': []\n"
     ]
    }
   ],
   "source": [
    "# Import module\n",
    "from nrclex import NRCLex\n",
    "\n",
    "# Get all Words with 'no emotes'\n",
    "noEmoteWords = dict()\n",
    "for word in id2word:\n",
    "    emotion = NRCLex(id2word[word])\n",
    "    if len(emotion.affect_list) == 0:\n",
    "        noEmoteWords[word]=id2word[word]\n",
    "\n",
    "print('All words in IMDB dataset:', len(id2word))\n",
    "print('Words without emotes in IMDB dataset:', len(noEmoteWords))\n",
    "print('Example - \\'love\\':', NRCLex('love').affect_list)\n",
    "print('Example - \\'not\\':', NRCLex('not').affect_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0666eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all 'No Emote Words' from sentence\n",
    "def NullNoEmoteWords(X, noEmoteWords):\n",
    "    for idx in range(len(X)):\n",
    "        if X[idx] in noEmoteWords:\n",
    "            X[idx] = 0\n",
    "    X = [s for s in X if s != 0]\n",
    "    return X\n",
    "\n",
    "# Delete all 'No Emote Words' form data\n",
    "def OnlyEmoteWords(X, noEmoteWords):\n",
    "    for idx in range(len(X)):\n",
    "        X[idx] = NullNoEmoteWords(X[idx], noEmoteWords)\n",
    "    return X\n",
    "\n",
    "# Delete 'No Emote Words'\n",
    "xTrain = OnlyEmoteWords(xTrain, noEmoteWords.keys())\n",
    "xTest = OnlyEmoteWords(xTest, noEmoteWords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96094e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select maximum number of words as input lengt\n",
    "# pad or truncated (this is done automatically) your data\n",
    "maxWords = 200\n",
    "xTrain = sequence.pad_sequences(xTrain, maxlen=maxWords)\n",
    "xTest = sequence.pad_sequences(xTest, maxlen=maxWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef171ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 200, 4)            100000    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 4)                 144       \n",
      "                                                                 \n",
      " layer_normalization_7 (Laye  (None, 4)                8         \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,157\n",
      "Trainable params: 100,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## setup the neural network architecture\n",
    "model=Sequential()\n",
    " \n",
    "embeddingSize = 4\n",
    "model.add(Embedding(vocabularySize, embeddingSize, embeddings_initializer='HeNormal', input_length=maxWords))\n",
    "\n",
    "# add layers: \n",
    "\n",
    "# model.add(SimpleRNN(100))\n",
    "model.add(LSTM(4))\n",
    "model.add(LayerNormalization())\n",
    "\n",
    "# add layer for output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# print model and check number of parameters\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18535444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "390/390 [==============================] - 16s 37ms/step - loss: 0.5112 - accuracy: 0.7468 - val_loss: 0.3763 - val_accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 14s 35ms/step - loss: 0.3932 - accuracy: 0.8269 - val_loss: 0.3375 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 14s 36ms/step - loss: 0.3542 - accuracy: 0.8491 - val_loss: 0.3302 - val_accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 14s 36ms/step - loss: 0.3270 - accuracy: 0.8647 - val_loss: 0.3766 - val_accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 14s 36ms/step - loss: 0.3036 - accuracy: 0.8786 - val_loss: 0.3330 - val_accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 14s 36ms/step - loss: 0.2845 - accuracy: 0.8870 - val_loss: 0.3673 - val_accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 14s 35ms/step - loss: 0.2713 - accuracy: 0.8944 - val_loss: 0.3600 - val_accuracy: 0.8281\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 14s 35ms/step - loss: 0.2573 - accuracy: 0.9023 - val_loss: 0.3536 - val_accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 14s 35ms/step - loss: 0.2463 - accuracy: 0.9076 - val_loss: 0.3951 - val_accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 14s 35ms/step - loss: 0.2387 - accuracy: 0.9123 - val_loss: 0.4119 - val_accuracy: 0.8438\n",
      "Test accuracy: 0.7497199773788452\n"
     ]
    }
   ],
   "source": [
    "# set parameters for network training\n",
    "batchSize = 64\n",
    "numEpochs = 10\n",
    "\n",
    "# train your model\n",
    "model.compile(loss='binary_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
    "xValid, yValid = xTrain[:batchSize], yTrain[:batchSize]\n",
    "xTrain2, yTrain2 = xTrain[batchSize:], yTrain[batchSize:]\n",
    "hist = model.fit(xTrain2, yTrain2, validation_data=(xValid, yValid), batch_size=batchSize, epochs=numEpochs)\n",
    "\n",
    "# check result\n",
    "scores = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('FinalResult')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
